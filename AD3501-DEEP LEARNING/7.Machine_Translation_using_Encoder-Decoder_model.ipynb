{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":610},"executionInfo":{"elapsed":445,"status":"error","timestamp":1730790658142,"user":{"displayName":"Mix Master","userId":"09511533599127285786"},"user_tz":-330},"id":"3pYTZMWDQOA4","outputId":"1fa980db-f553-4596-9265-23a77443d476"},"outputs":[{"name":"stdout","output_type":"stream","text":["First few lines of the file:\n","Line 1: Go.    Va !\n","Line 2: Hi.    Salut !\n","Line 3: Run!    Cours !\n","Line 4: Wait!    Attends !\n","Line 5: Hello!    Bonjour !\n","Line 6: I see.    Je vois.\n","Line 7: Nice.    Sympa.\n","Line 8: Yes.    Oui.\n","Line 9: No.    Non.\n","Line 10: Thanks.    Merci.\n","Skipping line (not properly formatted): Go.    Va !\n","Skipping line (not properly formatted): Hi.    Salut !\n","Skipping line (not properly formatted): Run!    Cours !\n","Skipping line (not properly formatted): Wait!    Attends !\n","Skipping line (not properly formatted): Hello!    Bonjour !\n","Skipping line (not properly formatted): I see.    Je vois.\n","Skipping line (not properly formatted): Nice.    Sympa.\n","Skipping line (not properly formatted): Yes.    Oui.\n","Skipping line (not properly formatted): No.    Non.\n","Skipping line (not properly formatted): Thanks.    Merci.\n","Number of input texts: 0\n","Number of target texts: 0\n"]},{"ename":"ValueError","evalue":"max() arg is an empty sequence","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-9-aeca894da427\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 20\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# Proceed to calculate sequence lengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 63\u001b[0;31m     \u001b[0mmax_encoder_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtxt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_texts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mmax_decoder_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtxt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_texts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"]}],"source":["import numpy as np\n","import os\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense\n","\n","# Parameters\n","batch_size = 64\n","epochs = 100\n","latent_dim = 256  # Hidden state dimension\n","num_samples = 10000\n","data_path = '/content/fra.txt'\n","\n","# Initialize data structures\n","input_texts = []\n","target_texts = []\n","input_characters = set()\n","target_characters = set()\n","\n","# Verify that the file exists and is being read correctly\n","if os.path.exists(data_path):\n","    with open(data_path, 'r', encoding='utf-8') as f:\n","        lines = f.read().split('\\n')\n","\n","    # Print the first few lines to check the content\n","    print(\"First few lines of the file:\")\n","    for i, line in enumerate(lines[:10]):\n","        print(f\"Line {i + 1}: {line}\")\n","\n","    # Process the data\n","    for line in lines[:min(num_samples, len(lines) - 1)]:\n","        line = line.strip()  # Remove leading/trailing whitespace\n","        parts = line.split('\\t')\n","\n","        # Ensure the line has both input and target sentences\n","        if len(parts) \u003c 2:\n","            print(f\"Skipping line (not properly formatted): {line}\")\n","            continue\n","\n","        input_text = parts[0]\n","        target_text = parts[1]\n","\n","        # Add special start and end tokens for the target text\n","        target_text = '\\t' + target_text + '\\n'\n","\n","        input_texts.append(input_text)\n","        target_texts.append(target_text)\n","\n","        # Collect unique characters in input and target texts\n","        for char in input_text:\n","            if char not in input_characters:\n","                input_characters.add(char)\n","        for char in target_text:\n","            if char not in target_characters:\n","                target_characters.add(char)\n","\n","    # Debugging print statements to check input_texts and target_texts\n","    print(f\"Number of input texts: {len(input_texts)}\")\n","    print(f\"Number of target texts: {len(target_texts)}\")\n","\n","    # Check if input_texts or target_texts are empty\n","    if not input_texts or not target_texts:\n","        raise ValueError(\"input_texts or target_texts is empty\")\n","\n","    # Proceed to calculate sequence lengths\n","    max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","    max_decoder_seq_length = max([len(txt) for txt in target_texts])\n","\n","    print('Number of samples:', len(input_texts))\n","    print('Number of unique input tokens:', len(input_characters))\n","    print('Number of unique output tokens:', len(target_characters))\n","    print('Max sequence length for inputs:', max_encoder_seq_length)\n","    print('Max sequence length for outputs:', max_decoder_seq_length)\n","\n","    # Create token index dictionaries\n","    input_token_index = dict([(char, i) for i, char in enumerate(sorted(input_characters))])\n","    target_token_index = dict([(char, i) for i, char in enumerate(sorted(target_characters))])\n","\n","    # Initialize encoder and decoder data arrays\n","    encoder_input_data = np.zeros(\n","        (len(input_texts), max_encoder_seq_length, len(input_characters)),\n","        dtype='float32'\n","    )\n","    decoder_input_data = np.zeros(\n","        (len(input_texts), max_decoder_seq_length, len(target_characters)),\n","        dtype='float32'\n","    )\n","    decoder_target_data = np.zeros(\n","        (len(input_texts), max_decoder_seq_length, len(target_characters)),\n","        dtype='float32'\n","    )\n","\n","    # Populate the data arrays\n","    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","        for t, char in enumerate(input_text):\n","            encoder_input_data[i, t, input_token_index[char]] = 1.\n","        for t, char in enumerate(target_text):\n","            decoder_input_data[i, t, target_token_index[char]] = 1.\n","            if t \u003e 0:\n","                # decoder_target_data is ahead of decoder_input_data by one timestep\n","                decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n","\n","    # Define the model\n","    # Encoder\n","    encoder_inputs = Input(shape=(None, len(input_characters)))\n","    encoder = LSTM(latent_dim, return_state=True)\n","    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","    encoder_states = [state_h, state_c]\n","\n","    # Decoder\n","    decoder_inputs = Input(shape=(None, len(target_characters)))\n","    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","    decoder_dense = Dense(len(target_characters), activation='softmax')\n","    decoder_outputs = decoder_dense(decoder_outputs)\n","\n","    # Define the full model\n","    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","    # Compile and train the model\n","    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","    model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_split=0.2)\n","else:\n","    print(f\"File not found: {data_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"csaFPWy3JWqK"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0139 - loss: 1.6853 - val_accuracy: 0.0278 - val_loss: 1.1509\n","Epoch 2/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.0764 - loss: 1.6773 - val_accuracy: 0.0278 - val_loss: 1.1495\n","Epoch 3/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.0833 - loss: 1.6704 - val_accuracy: 0.0000e+00 - val_loss: 1.1480\n","Epoch 4/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.0972 - loss: 1.6635 - val_accuracy: 0.0000e+00 - val_loss: 1.1463\n","Epoch 5/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.0972 - loss: 1.6561 - val_accuracy: 0.0000e+00 - val_loss: 1.1442\n","Epoch 6/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.0972 - loss: 1.6475 - val_accuracy: 0.0000e+00 - val_loss: 1.1411\n","Epoch 7/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.0972 - loss: 1.6362 - val_accuracy: 0.0000e+00 - val_loss: 1.1363\n","Epoch 8/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.1042 - loss: 1.6191 - val_accuracy: 0.0000e+00 - val_loss: 1.1273\n","Epoch 9/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.1042 - loss: 1.5884 - val_accuracy: 0.0278 - val_loss: 1.1116\n","Epoch 10/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.1042 - loss: 1.5443 - val_accuracy: 0.0000e+00 - val_loss: 1.1009\n","Epoch 11/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.0972 - loss: 1.5221 - val_accuracy: 0.0556 - val_loss: 1.0871\n","Epoch 12/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.0903 - loss: 1.5018 - val_accuracy: 0.0556 - val_loss: 1.0770\n","Epoch 13/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.0972 - loss: 1.4859 - val_accuracy: 0.0278 - val_loss: 1.0713\n","Epoch 14/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.0972 - loss: 1.4758 - val_accuracy: 0.0000e+00 - val_loss: 1.0704\n","Epoch 15/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.0903 - loss: 1.4680 - val_accuracy: 0.0000e+00 - val_loss: 1.0696\n","Epoch 16/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.0625 - loss: 1.4646 - val_accuracy: 0.0000e+00 - val_loss: 1.0696\n","Epoch 17/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.0625 - loss: 1.4583 - val_accuracy: 0.0000e+00 - val_loss: 1.0678\n","Epoch 18/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.0625 - loss: 1.4555 - val_accuracy: 0.0000e+00 - val_loss: 1.0683\n","Epoch 19/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.0625 - loss: 1.4479 - val_accuracy: 0.0000e+00 - val_loss: 1.0661\n","Epoch 20/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.0625 - loss: 1.4450 - val_accuracy: 0.0000e+00 - val_loss: 1.0660\n","Epoch 21/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.0625 - loss: 1.4361 - val_accuracy: 0.0000e+00 - val_loss: 1.0626\n","Epoch 22/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.0625 - loss: 1.4325 - val_accuracy: 0.0000e+00 - val_loss: 1.0637\n","Epoch 23/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.0625 - loss: 1.4225 - val_accuracy: 0.0000e+00 - val_loss: 1.0575\n","Epoch 24/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.0625 - loss: 1.4206 - val_accuracy: 0.0000e+00 - val_loss: 1.0581\n","Epoch 25/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.0625 - loss: 1.4113 - val_accuracy: 0.0000e+00 - val_loss: 1.0570\n","Epoch 26/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.0625 - loss: 1.4060 - val_accuracy: 0.0000e+00 - val_loss: 1.0576\n","Epoch 27/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.0625 - loss: 1.3980 - val_accuracy: 0.0000e+00 - val_loss: 1.0574\n","Epoch 28/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.0764 - loss: 1.3915 - val_accuracy: 0.0000e+00 - val_loss: 1.0588\n","Epoch 29/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.0764 - loss: 1.3843 - val_accuracy: 0.0000e+00 - val_loss: 1.0573\n","Epoch 30/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.0764 - loss: 1.3775 - val_accuracy: 0.0000e+00 - val_loss: 1.0610\n","Epoch 31/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.0903 - loss: 1.3715 - val_accuracy: 0.0000e+00 - val_loss: 1.0548\n","Epoch 32/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.0833 - loss: 1.3641 - val_accuracy: 0.0000e+00 - val_loss: 1.0649\n","Epoch 33/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.0833 - loss: 1.3596 - val_accuracy: 0.0278 - val_loss: 1.0607\n","Epoch 34/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.0903 - loss: 1.3473 - val_accuracy: 0.0000e+00 - val_loss: 1.0613\n","Epoch 35/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.0833 - loss: 1.3496 - val_accuracy: 0.0000e+00 - val_loss: 1.0663\n","Epoch 36/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.0972 - loss: 1.3301 - val_accuracy: 0.0000e+00 - val_loss: 1.0615\n","Epoch 37/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.0764 - loss: 1.3541 - val_accuracy: 0.0000e+00 - val_loss: 1.0777\n","Epoch 38/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.0972 - loss: 1.3227 - val_accuracy: 0.0556 - val_loss: 1.0497\n","Epoch 39/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.0833 - loss: 1.3390 - val_accuracy: 0.0000e+00 - val_loss: 1.0640\n","Epoch 40/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.1042 - loss: 1.3064 - val_accuracy: 0.0000e+00 - val_loss: 1.0575\n","Epoch 41/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.0972 - loss: 1.3340 - val_accuracy: 0.0000e+00 - val_loss: 1.0780\n","Epoch 42/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.0903 - loss: 1.3033 - val_accuracy: 0.0000e+00 - val_loss: 1.0621\n","Epoch 43/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.0764 - loss: 1.3398 - val_accuracy: 0.0000e+00 - val_loss: 1.0731\n","Epoch 44/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.0972 - loss: 1.2872 - val_accuracy: 0.0000e+00 - val_loss: 1.0647\n","Epoch 45/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.0972 - loss: 1.2811 - val_accuracy: 0.0000e+00 - val_loss: 1.0905\n","Epoch 46/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.0833 - loss: 1.2827 - val_accuracy: 0.0000e+00 - val_loss: 1.0710\n","Epoch 47/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.0833 - loss: 1.3649 - val_accuracy: 0.0000e+00 - val_loss: 1.0604\n","Epoch 48/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.1042 - loss: 1.3033 - val_accuracy: 0.0000e+00 - val_loss: 1.0765\n","Epoch 49/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.1181 - loss: 1.2673 - val_accuracy: 0.0000e+00 - val_loss: 1.0634\n","Epoch 50/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.0972 - loss: 1.2763 - val_accuracy: 0.0000e+00 - val_loss: 1.0922\n","Epoch 51/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.0972 - loss: 1.2615 - val_accuracy: 0.0000e+00 - val_loss: 1.0728\n","Epoch 52/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.0764 - loss: 1.3556 - val_accuracy: 0.0000e+00 - val_loss: 1.0610\n","Epoch 53/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.1042 - loss: 1.3033 - val_accuracy: 0.0000e+00 - val_loss: 1.0730\n","Epoch 54/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.1181 - loss: 1.2611 - val_accuracy: 0.0000e+00 - val_loss: 1.0829\n","Epoch 55/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1181 - loss: 1.2468 - val_accuracy: 0.0000e+00 - val_loss: 1.0802\n","Epoch 56/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.1181 - loss: 1.2335 - val_accuracy: 0.0000e+00 - val_loss: 1.0894\n","Epoch 57/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.1181 - loss: 1.2207 - val_accuracy: 0.0000e+00 - val_loss: 1.0678\n","Epoch 58/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.1181 - loss: 1.2491 - val_accuracy: 0.0000e+00 - val_loss: 1.1510\n","Epoch 59/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1042 - loss: 1.3014 - val_accuracy: 0.0000e+00 - val_loss: 1.1028\n","Epoch 60/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.0694 - loss: 1.3852 - val_accuracy: 0.0000e+00 - val_loss: 1.0833\n","Epoch 61/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.0833 - loss: 1.3501 - val_accuracy: 0.0000e+00 - val_loss: 1.0705\n","Epoch 62/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.0972 - loss: 1.3244 - val_accuracy: 0.0000e+00 - val_loss: 1.0700\n","Epoch 63/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1111 - loss: 1.3015 - val_accuracy: 0.0000e+00 - val_loss: 1.0673\n","Epoch 64/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.1250 - loss: 1.2793 - val_accuracy: 0.0000e+00 - val_loss: 1.0671\n","Epoch 65/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.1250 - loss: 1.2597 - val_accuracy: 0.0000e+00 - val_loss: 1.0702\n","Epoch 66/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.1319 - loss: 1.2439 - val_accuracy: 0.0000e+00 - val_loss: 1.0732\n","Epoch 67/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1389 - loss: 1.2309 - val_accuracy: 0.0000e+00 - val_loss: 1.0756\n","Epoch 68/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.1458 - loss: 1.2194 - val_accuracy: 0.0000e+00 - val_loss: 1.0772\n","Epoch 69/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.1458 - loss: 1.2090 - val_accuracy: 0.0000e+00 - val_loss: 1.0793\n","Epoch 70/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.1458 - loss: 1.1989 - val_accuracy: 0.0000e+00 - val_loss: 1.0817\n","Epoch 71/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1319 - loss: 1.1893 - val_accuracy: 0.0000e+00 - val_loss: 1.0844\n","Epoch 72/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.1319 - loss: 1.1808 - val_accuracy: 0.0000e+00 - val_loss: 1.0883\n","Epoch 73/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.1319 - loss: 1.1723 - val_accuracy: 0.0000e+00 - val_loss: 1.0910\n","Epoch 74/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.1319 - loss: 1.1628 - val_accuracy: 0.0000e+00 - val_loss: 1.0969\n","Epoch 75/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.1389 - loss: 1.1598 - val_accuracy: 0.0000e+00 - val_loss: 1.1026\n","Epoch 76/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.1597 - loss: 1.1404 - val_accuracy: 0.0556 - val_loss: 1.0761\n","Epoch 77/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.1250 - loss: 1.2158 - val_accuracy: 0.0000e+00 - val_loss: 1.1148\n","Epoch 78/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.1250 - loss: 1.2209 - val_accuracy: 0.0000e+00 - val_loss: 1.0954\n","Epoch 79/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.1042 - loss: 1.3024 - val_accuracy: 0.0000e+00 - val_loss: 1.0814\n","Epoch 80/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - accuracy: 0.1250 - loss: 1.2336 - val_accuracy: 0.0000e+00 - val_loss: 1.1081\n","Epoch 81/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.1597 - loss: 1.1788 - val_accuracy: 0.0000e+00 - val_loss: 1.1076\n","Epoch 82/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.1597 - loss: 1.1559 - val_accuracy: 0.0000e+00 - val_loss: 1.1179\n","Epoch 83/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step - accuracy: 0.1736 - loss: 1.1352 - val_accuracy: 0.0000e+00 - val_loss: 1.0947\n","Epoch 84/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.1597 - loss: 1.1375 - val_accuracy: 0.0000e+00 - val_loss: 1.2014\n","Epoch 85/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.1458 - loss: 1.2028 - val_accuracy: 0.0556 - val_loss: 1.1338\n","Epoch 86/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670ms/step - accuracy: 0.0903 - loss: 1.3388 - val_accuracy: 0.0000e+00 - val_loss: 1.1094\n","Epoch 87/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step - accuracy: 0.1181 - loss: 1.2886 - val_accuracy: 0.0000e+00 - val_loss: 1.0896\n","Epoch 88/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.1458 - loss: 1.2398 - val_accuracy: 0.0000e+00 - val_loss: 1.0770\n","Epoch 89/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649ms/step - accuracy: 0.1597 - loss: 1.1933 - val_accuracy: 0.0278 - val_loss: 1.0825\n","Epoch 90/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - accuracy: 0.1528 - loss: 1.1579 - val_accuracy: 0.0000e+00 - val_loss: 1.0891\n","Epoch 91/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.1736 - loss: 1.1334 - val_accuracy: 0.0000e+00 - val_loss: 1.0984\n","Epoch 92/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.1597 - loss: 1.1178 - val_accuracy: 0.0000e+00 - val_loss: 1.1078\n","Epoch 93/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.1667 - loss: 1.0999 - val_accuracy: 0.0000e+00 - val_loss: 1.1063\n","Epoch 94/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.1667 - loss: 1.0976 - val_accuracy: 0.0000e+00 - val_loss: 1.1291\n","Epoch 95/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.1736 - loss: 1.0752 - val_accuracy: 0.0278 - val_loss: 1.1012\n","Epoch 96/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.1944 - loss: 1.1280 - val_accuracy: 0.0000e+00 - val_loss: 1.1579\n","Epoch 97/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1667 - loss: 1.1172 - val_accuracy: 0.0278 - val_loss: 1.1238\n","Epoch 98/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1389 - loss: 1.2269 - val_accuracy: 0.0278 - val_loss: 1.1205\n","Epoch 99/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.1458 - loss: 1.1178 - val_accuracy: 0.0000e+00 - val_loss: 1.1523\n","Epoch 100/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1875 - loss: 1.0690 - val_accuracy: 0.0000e+00 - val_loss: 1.1310\n"]},{"ename":"InvalidArgumentError","evalue":"Graph execution error:\n\nDetected at node functional_8_1/lstm_8_1/while/lstm_cell_1/MatMul defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in \u003cmodule\u003e\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in \u003clambda\u003e\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"\u003cipython-input-12-36d066d341da\u003e\", line 111, in \u003ccell line: 109\u003e\n\n  File \"\u003cipython-input-11-b02a6d5bd210\u003e\", line 81, in decode_sequence\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 508, in predict\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 208, in one_step_on_data_distributed\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 198, in one_step_on_data\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 96, in predict_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\", line 882, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\", line 175, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\", line 556, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\", line 882, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/lstm.py\", line 570, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py\", line 406, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/lstm.py\", line 565, in inner_loop\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py\", line 346, in inner_loop\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 428, in rnn\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 411, in _step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py\", line 338, in step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\", line 882, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/lstm.py\", line 264, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/numpy.py\", line 3445, in matmul\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/numpy.py\", line 477, in matmul\n\nMatrix size-incompatible: In[0]: [1,22], In[1]: [7,1024]\n\t [[{{node functional_8_1/lstm_8_1/while/lstm_cell_1/MatMul}}]] [Op:__inference_one_step_on_data_distributed_50548]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-12-36d066d341da\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 109\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 111\u001b[0;31m     \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input sentence:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Decoded sentence:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-11-b02a6d5bd210\u003e\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# Function to decode sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 81\u001b[0;31m     \u001b[0mstates_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtarget_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_decoder_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# The token 'startseq' doesn't exist, start with the first token instead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_8_1/lstm_8_1/while/lstm_cell_1/MatMul defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in \u003cmodule\u003e\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in \u003clambda\u003e\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"\u003cipython-input-12-36d066d341da\u003e\", line 111, in \u003ccell line: 109\u003e\n\n  File \"\u003cipython-input-11-b02a6d5bd210\u003e\", line 81, in decode_sequence\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 508, in predict\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 208, in one_step_on_data_distributed\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 198, in one_step_on_data\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 96, in predict_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\", line 882, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\", line 175, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\", line 556, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\", line 882, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/lstm.py\", line 570, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py\", line 406, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/lstm.py\", line 565, in inner_loop\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py\", line 346, in inner_loop\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 428, in rnn\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 411, in _step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py\", line 338, in step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\", line 882, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/lstm.py\", line 264, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/numpy.py\", line 3445, in matmul\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/numpy.py\", line 477, in matmul\n\nMatrix size-incompatible: In[0]: [1,22], In[1]: [7,1024]\n\t [[{{node functional_8_1/lstm_8_1/while/lstm_cell_1/MatMul}}]] [Op:__inference_one_step_on_data_distributed_50548]"]}],"source":["import numpy as np\n","import os\n","import logging\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense\n","\n","# Initialize logging\n","logging.basicConfig(level=logging.INFO)\n","\n","# Parameters\n","batch_size = 64\n","epochs = 100\n","latent_dim = 256  # Hidden state dimension\n","num_samples = 10000\n","data_path = '/content/fra.txt'\n","\n","# Initialize data structures\n","input_texts = []\n","target_texts = []\n","input_characters = set()\n","target_characters = set()\n","\n","# Function to load and preprocess data\n","def load_data(data_path, num_samples):\n","    if not os.path.exists(data_path):\n","        raise FileNotFoundError(f\"File not found: {data_path}\")\n","\n","    with open(data_path, 'r', encoding='utf-8') as f:\n","        lines = f.read().split('\\n')\n","\n","    logging.info(\"First few lines of the file:\")\n","    for i, line in enumerate(lines[:10]):\n","        logging.info(f\"Line {i + 1}: {line}\")\n","\n","    input_texts = []\n","    target_texts = []\n","    input_characters = set()\n","    target_characters = set()\n","\n","    for line in lines[:min(num_samples, len(lines) - 1)]:\n","        line = line.strip()  # Remove leading/trailing whitespace\n","        # Split line by any whitespace (space or tab)\n","        parts = line.split(maxsplit=1)\n","        if len(parts) \u003c 2:\n","            logging.warning(f\"Skipping line (not properly formatted): {line}\")\n","            continue\n","        input_text = parts[0].strip()\n","        target_text = '\\t' + parts[1].strip() + '\\n'\n","        input_texts.append(input_text)\n","        target_texts.append(target_text)\n","        input_characters.update(set(input_text))\n","        target_characters.update(set(target_text))\n","\n","    if not input_texts or not target_texts:\n","        raise ValueError(\"input_texts or target_texts is empty\")\n","\n","    return input_texts, target_texts, input_characters, target_characters\n","\n","# Function to vectorize data\n","def vectorize_data(input_texts, target_texts, input_characters, target_characters):\n","    max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","    max_decoder_seq_length = max([len(txt) for txt in target_texts])\n","    input_token_index = {char: i for i, char in enumerate(sorted(input_characters))}\n","    target_token_index = {char: i for i, char in enumerate(sorted(target_characters))}\n","\n","    encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, len(input_characters)), dtype='float32')\n","    decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, len(target_characters)), dtype='float32')\n","    decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, len(target_characters)), dtype='float32')\n","\n","    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","        for t, char in enumerate(input_text):\n","            encoder_input_data[i, t, input_token_index[char]] = 1.\n","        for t, char in enumerate(target_text):\n","            decoder_input_data[i, t, target_token_index[char]] = 1.\n","            if t \u003e 0:\n","                decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n","\n","    return encoder_input_data, decoder_input_data, decoder_target_data, max_encoder_seq_length, max_decoder_seq_length, input_token_index, target_token_index\n","\n","# Load and preprocess data\n","input_texts, target_texts, input_characters, target_characters = load_data(data_path, num_samples)\n","\n","# Vectorize data\n","encoder_input_data, decoder_input_data, decoder_target_data, max_encoder_seq_length, max_decoder_seq_length, input_token_index, target_token_index = vectorize_data(input_texts, target_texts, input_characters, target_characters)\n","\n","# Define the model\n","# Encoder\n","encoder_inputs = Input(shape=(None, len(input_characters)))\n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","encoder_states = [state_h, state_c]\n","\n","# Decoder\n","decoder_inputs = Input(shape=(None, len(target_characters)))\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","decoder_dense = Dense(len(target_characters), activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Define the full model\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","# Compile and train the model\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_split=0.2)\n","for seq_index in range(10):\n","    input_seq = encoder_input_data[seq_index: seq_index + 1]\n","    decoded_sentence = decode_sequence(input_seq)\n","    print('Input sentence:', input_texts[seq_index])\n","    print('Decoded sentence:', decoded_sentence)\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":16618,"status":"error","timestamp":1730790708299,"user":{"displayName":"Mix Master","userId":"09511533599127285786"},"user_tz":-330},"id":"FMw1BEF0QuqL","outputId":"17cf4acc-160d-41ea-ad0b-5d9f828e4a7b"},"outputs":[{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003eModel: \"functional_7\"\u003c/span\u003e\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1mModel: \"functional_7\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u003cspan style=\"font-weight: bold\"\u003e Layer (type)              \u003c/span\u003e┃\u003cspan style=\"font-weight: bold\"\u003e Output Shape           \u003c/span\u003e┃\u003cspan style=\"font-weight: bold\"\u003e        Param # \u003c/span\u003e┃\u003cspan style=\"font-weight: bold\"\u003e Connected to           \u003c/span\u003e┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_10            │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e)        │              \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │ -                      │\n","│ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eInputLayer\u003c/span\u003e)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ input_layer_11            │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e)        │              \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │ -                      │\n","│ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eInputLayer\u003c/span\u003e)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lstm_8 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eLSTM\u003c/span\u003e)             │ [(\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e256\u003c/span\u003e), (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e,   │        \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e270,336\u003c/span\u003e │ input_layer_10[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]   │\n","│                           │ \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e256\u003c/span\u003e), (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e256\u003c/span\u003e)]     │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lstm_9 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eLSTM\u003c/span\u003e)             │ [(\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e256\u003c/span\u003e),    │        \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e270,336\u003c/span\u003e │ input_layer_11[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e],  │\n","│                           │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e256\u003c/span\u003e), (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e,    │                │ lstm_8[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1\u003c/span\u003e],          │\n","│                           │ \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e256\u003c/span\u003e)]                  │                │ lstm_8[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2\u003c/span\u003e]           │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense_4 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDense\u003c/span\u003e)           │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e)        │          \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1,799\u003c/span\u003e │ lstm_9[\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e][\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e]           │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","\u003c/pre\u003e\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_10            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ input_layer_11            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │        \u001b[38;5;34m270,336\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","│                           │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]     │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),    │        \u001b[38;5;34m270,336\u001b[0m │ input_layer_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n","│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ lstm_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],          │\n","│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │ lstm_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]           │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)        │          \u001b[38;5;34m1,799\u001b[0m │ lstm_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Total params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e542,471\u003c/span\u003e (2.07 MB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m542,471\u001b[0m (2.07 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Trainable params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e542,471\u003c/span\u003e (2.07 MB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m542,471\u001b[0m (2.07 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Non-trainable params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e (0.00 B)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 1.2998 - val_loss: 1.2943\n","Epoch 2/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 1.2475 - val_loss: 1.2854\n","Epoch 3/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 1.2068 - val_loss: 1.2768\n","Epoch 4/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 1.1692 - val_loss: 1.2680\n","Epoch 5/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.1319 - val_loss: 1.2583\n","Epoch 6/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.0938 - val_loss: 1.2477\n","Epoch 7/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 1.0539 - val_loss: 1.2361\n","Epoch 8/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 1.0118 - val_loss: 1.2234\n","Epoch 9/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.9675 - val_loss: 1.2099\n","Epoch 10/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.9213 - val_loss: 1.1962\n","Epoch 11/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.8741 - val_loss: 1.1831\n","Epoch 12/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.8270 - val_loss: 1.1717\n","Epoch 13/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.7815 - val_loss: 1.1628\n","Epoch 14/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.7388 - val_loss: 1.1569\n","Epoch 15/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.6995 - val_loss: 1.1537\n","Epoch 16/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.6636 - val_loss: 1.1525\n","Epoch 17/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.6308 - val_loss: 1.1525\n","Epoch 18/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 0.6005 - val_loss: 1.1532\n","Epoch 19/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.5726 - val_loss: 1.1542\n","Epoch 20/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.5469 - val_loss: 1.1557\n","Epoch 21/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.5233 - val_loss: 1.1578\n","Epoch 22/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.5018 - val_loss: 1.1611\n","Epoch 23/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.4827 - val_loss: 1.1660\n","Epoch 24/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.4660 - val_loss: 1.1732\n","Epoch 25/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.4518 - val_loss: 1.1837\n","Epoch 26/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4399 - val_loss: 1.1984\n","Epoch 27/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.4298 - val_loss: 1.2179\n","Epoch 28/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4208 - val_loss: 1.2421\n","Epoch 29/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4120 - val_loss: 1.2700\n","Epoch 30/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.4028 - val_loss: 1.3000\n","Epoch 31/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3926 - val_loss: 1.3301\n","Epoch 32/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3810 - val_loss: 1.3588\n","Epoch 33/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.3680 - val_loss: 1.3855\n","Epoch 34/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3538 - val_loss: 1.4098\n","Epoch 35/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3384 - val_loss: 1.4313\n","Epoch 36/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3225 - val_loss: 1.4501\n","Epoch 37/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3061 - val_loss: 1.4665\n","Epoch 38/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.2898 - val_loss: 1.4810\n","Epoch 39/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.2738 - val_loss: 1.4938\n","Epoch 40/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.2584 - val_loss: 1.5054\n","Epoch 41/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.2439 - val_loss: 1.5156\n","Epoch 42/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2305 - val_loss: 1.5254\n","Epoch 43/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2181 - val_loss: 1.5327\n","Epoch 44/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2073 - val_loss: 1.5428\n","Epoch 45/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.1966 - val_loss: 1.5434\n","Epoch 46/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.1893 - val_loss: 1.5646\n","Epoch 47/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1776 - val_loss: 1.5396\n","Epoch 48/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.1797 - val_loss: 1.6005\n","Epoch 49/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.1639 - val_loss: 1.5393\n","Epoch 50/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.1730 - val_loss: 1.6094\n","Epoch 51/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.1551 - val_loss: 1.5589\n","Epoch 52/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1561 - val_loss: 1.6029\n","Epoch 53/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.1431 - val_loss: 1.5742\n","Epoch 54/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.1429 - val_loss: 1.6058\n","Epoch 55/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1341 - val_loss: 1.5851\n","Epoch 56/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.1336 - val_loss: 1.6134\n","Epoch 57/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1266 - val_loss: 1.5936\n","Epoch 58/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.1267 - val_loss: 1.6228\n","Epoch 59/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1201 - val_loss: 1.6005\n","Epoch 60/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1218 - val_loss: 1.6327\n","Epoch 61/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.1143 - val_loss: 1.6068\n","Epoch 62/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1183 - val_loss: 1.6417\n","Epoch 63/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.1092 - val_loss: 1.6139\n","Epoch 64/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1150 - val_loss: 1.6483\n","Epoch 65/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.1051 - val_loss: 1.6218\n","Epoch 66/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.1111 - val_loss: 1.6531\n","Epoch 67/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.1016 - val_loss: 1.6300\n","Epoch 68/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.1072 - val_loss: 1.6577\n","Epoch 69/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0986 - val_loss: 1.6378\n","Epoch 70/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.1039 - val_loss: 1.6630\n","Epoch 71/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0960 - val_loss: 1.6452\n","Epoch 72/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.1013 - val_loss: 1.6690\n","Epoch 73/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0937 - val_loss: 1.6521\n","Epoch 74/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0993 - val_loss: 1.6753\n","Epoch 75/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0918 - val_loss: 1.6589\n","Epoch 76/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0977 - val_loss: 1.6816\n","Epoch 77/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0902 - val_loss: 1.6655\n","Epoch 78/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0963 - val_loss: 1.6876\n","Epoch 79/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0888 - val_loss: 1.6721\n","Epoch 80/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0949 - val_loss: 1.6931\n","Epoch 81/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0876 - val_loss: 1.6785\n","Epoch 82/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0936 - val_loss: 1.6981\n","Epoch 83/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0865 - val_loss: 1.6848\n","Epoch 84/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0923 - val_loss: 1.7030\n","Epoch 85/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0856 - val_loss: 1.6909\n","Epoch 86/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0912 - val_loss: 1.7078\n","Epoch 87/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0848 - val_loss: 1.6967\n","Epoch 88/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0903 - val_loss: 1.7126\n","Epoch 89/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0840 - val_loss: 1.7024\n","Epoch 90/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0896 - val_loss: 1.7173\n","Epoch 91/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0834 - val_loss: 1.7079\n","Epoch 92/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0889 - val_loss: 1.7217\n","Epoch 93/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0829 - val_loss: 1.7132\n","Epoch 94/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0884 - val_loss: 1.7260\n","Epoch 95/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0824 - val_loss: 1.7183\n","Epoch 96/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0878 - val_loss: 1.7301\n","Epoch 97/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0820 - val_loss: 1.7232\n","Epoch 98/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0873 - val_loss: 1.7339\n","Epoch 99/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0816 - val_loss: 1.7279\n","Epoch 100/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0869 - val_loss: 1.7376\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:5 out of the last 6 calls to \u003cfunction TensorFlowTrainer.make_predict_function.\u003clocals\u003e.one_step_on_data_distributed at 0x7ca5f2a8a950\u003e triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n"]},{"ename":"KeyError","evalue":"0","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-11-b02a6d5bd210\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 105\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 107\u001b[0;31m     \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input sentence:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-11-b02a6d5bd210\u003e\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0moutput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0msampled_token_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 92\u001b[0;31m         \u001b[0msampled_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msampled_token_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msampled_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 0"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense\n","\n","# Sample data\n","input_texts = [\"Hello\", \"How are you?\", \"Good morning\"]\n","target_texts = [\"Bonjour\", \"Comment ça va?\", \"Bon matin\"]\n","\n","# Tokenize the data\n","input_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n","target_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n","\n","input_tokenizer.fit_on_texts(input_texts)\n","target_tokenizer.fit_on_texts(target_texts)\n","\n","input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n","target_sequences = target_tokenizer.texts_to_sequences(target_texts)\n","\n","max_encoder_seq_length = max([len(seq) for seq in input_sequences])\n","max_decoder_seq_length = max([len(seq) for seq in target_sequences])\n","\n","num_encoder_tokens = len(input_tokenizer.word_index) + 1\n","num_decoder_tokens = len(target_tokenizer.word_index) + 1\n","\n","# Padding sequences\n","input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_encoder_seq_length, padding='post')\n","target_sequences = tf.keras.preprocessing.sequence.pad_sequences(target_sequences, maxlen=max_decoder_seq_length, padding='post')\n","\n","# One-hot encoding\n","encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n","decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n","decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n","\n","for i, (input_seq, target_seq) in enumerate(zip(input_sequences, target_sequences)):\n","    for t, word_index in enumerate(input_seq):\n","        encoder_input_data[i, t, word_index] = 1.\n","    for t, word_index in enumerate(target_seq):\n","        decoder_input_data[i, t, word_index] = 1.\n","        if t \u003e 0:\n","            decoder_target_data[i, t - 1, word_index] = 1.\n","\n","# Define the model\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder_lstm = LSTM(256, return_state=True)\n","encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n","encoder_states = [state_h, state_c]\n","\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","# Compile the model\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n","model.summary()\n","\n","# Train the model\n","model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=64, epochs=100, validation_split=0.2)\n","\n","# Inference models for prediction\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","decoder_state_input_h = Input(shape=(256,))\n","decoder_state_input_c = Input(shape=(256,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","decoder_outputs, state_h, state_c = decoder_lstm(\n","    decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states)\n","\n","# Function to decode sequences\n","def decode_sequence(input_seq):\n","    states_value = encoder_model.predict(input_seq)\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    # The token 'startseq' doesn't exist, start with the first token instead\n","    sampled_token_index = 0\n","    target_seq[0, 0, sampled_token_index] = 1.\n","\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_word = target_tokenizer.index_word[sampled_token_index]\n","        decoded_sentence += ' ' + sampled_word\n","\n","        if (sampled_word == 'endseq' or len(decoded_sentence) \u003e max_decoder_seq_length):\n","            stop_condition = True\n","\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.\n","        states_value = [h, c]\n","\n","    return decoded_sentence\n","\n","# Test the model\n","for seq_index in range(len(input_texts)):\n","    input_seq = encoder_input_data[seq_index: seq_index + 1]\n","    decoded_sentence = decode_sequence(input_seq)\n","    print('-')\n","    print('Input sentence:', input_texts[seq_index])\n","    print('Decoded sentence:', decoded_sentence)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_OBanCMiGHX"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense\n","\n","# Sample data\n","input_texts = [\"Hello\", \"How are you?\", \"Good morning\"]\n","target_texts = [\"Bonjour\", \"Comment ça va?\", \"Bon matin\"]\n","\n","# Tokenize the data\n","input_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n","target_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n","\n","input_tokenizer.fit_on_texts(input_texts)\n","target_tokenizer.fit_on_texts(target_texts)\n","\n","input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n","target_sequences = target_tokenizer.texts_to_sequences(target_texts)\n","\n","max_encoder_seq_length = max([len(seq) for seq in input_sequences])\n","max_decoder_seq_length = max([len(seq) for seq in target_sequences])\n","\n","num_encoder_tokens = len(input_tokenizer.word_index) + 1\n","num_decoder_tokens = len(target_tokenizer.word_index) + 1\n","\n","# Padding sequences\n","input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_encoder_seq_length, padding='post')\n","target_sequences = tf.keras.preprocessing.sequence.pad_sequences(target_sequences, maxlen=max_decoder_seq_length, padding='post')\n","\n","# One-hot encoding\n","encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n","decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n","decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n","\n","for i, (input_seq, target_seq) in enumerate(zip(input_sequences, target_sequences)):\n","    for t, word_index in enumerate(input_seq):\n","        encoder_input_data[i, t, word_index] = 1.\n","    for t, word_index in enumerate(target_seq):\n","        decoder_input_data[i, t, word_index] = 1.\n","        if t \u003e 0:\n","            decoder_target_data[i, t - 1, word_index] = 1.\n","\n","# Define the model\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder_lstm = LSTM(256, return_state=True)\n","encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n","encoder_states = [state_h, state_c]\n","\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","# Compile the model\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n","model.summary()\n","\n","# Train the model\n","model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=64, epochs=100, validation_split=0.2)\n","\n","# Inference models for prediction\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","decoder_state_input_h = Input\n","\n","# Test the model\n","for seq_index in range(len(input_texts)):\n","    input_seq = encoder_input_data[seq_index: seq_index + 1]\n","    decoded_sentence = decode_sequence(input_seq)\n","    print('-')\n","    print('Input sentence:', input_texts[seq_index])\n","    print('Decoded sentence:', decoded_sentence)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMM6uSrjPVD109JaH9UoBmI","mount_file_id":"1cfkiQa0T6Uj9rNrgIA1kMOiQrJvCHQS7","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}