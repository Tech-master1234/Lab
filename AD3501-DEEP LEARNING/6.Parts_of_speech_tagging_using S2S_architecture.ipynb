{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 12080,
     "status": "ok",
     "timestamp": 1730789978901,
     "user": {
      "displayName": "Mix Master",
      "userId": "09511533599127285786"
     },
     "user_tz": -330
    },
    "id": "f-FqfhAuzIqS"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.corpus import brown, treebank, conll2000\n",
    "import seaborn as sns\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Input, TimeDistributed, LSTM, GRU, Bidirectional, SimpleRNN, RNN\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1730789979289,
     "user": {
      "displayName": "Mix Master",
      "userId": "09511533599127285786"
     },
     "user_tz": -330
    },
    "id": "IIjYHh6FO7Ur",
    "outputId": "983129be-1b3d-45bf-fe6f-a26154961814"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/treebank.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 915,
     "status": "ok",
     "timestamp": 1730789980197,
     "user": {
      "displayName": "Mix Master",
      "userId": "09511533599127285786"
     },
     "user_tz": -330
    },
    "id": "dUrH-hTNSGMp",
    "outputId": "ef5e8e40-f5db-4b5f-8a1a-462149191d31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\manoj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\conll2000.zip.\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\manoj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\universal_tagset.zip.\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\manoj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\manoj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\treebank.zip.\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\manoj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download each corpus or resource individually\n",
    "nltk.download('conll2000')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('brown')\n",
    "nltk.download('treebank')\n",
    "nltk.download('universal_tagset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1730789980197,
     "user": {
      "displayName": "Mix Master",
      "userId": "09511533599127285786"
     },
     "user_tz": -330
    },
    "id": "_TIUxtVrO_0h",
    "outputId": "e7e6b6f4-296d-4fbb-f7b8-e8fa4099b373"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1730789980198,
     "user": {
      "displayName": "Mix Master",
      "userId": "09511533599127285786"
     },
     "user_tz": -330
    },
    "id": "IgvaiUWuPIFR",
    "outputId": "e4112ff5-cb43-4b60-ed80-f30fb9e56eae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('conll2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1730789980198,
     "user": {
      "displayName": "Mix Master",
      "userId": "09511533599127285786"
     },
     "user_tz": -330
    },
    "id": "y4d-Vw4jPWIz",
    "outputId": "660cd05b-a767-4800-986b-2d596f6500e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730789980198,
     "user": {
      "displayName": "Mix Master",
      "userId": "09511533599127285786"
     },
     "user_tz": -330
    },
    "id": "pPU2x2dx1LjS"
   },
   "outputs": [],
   "source": [
    "treebank_corpus = treebank.tagged_sents(tagset='universal')\n",
    "brown_corpus = brown.tagged_sents(tagset='universal')\n",
    "conll_corpus = conll2000.tagged_sents(tagset='universal')\n",
    "tagged_sentences = treebank_corpus + brown_corpus + conll_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11669,
     "status": "ok",
     "timestamp": 1730789991861,
     "user": {
      "displayName": "Mix Master",
      "userId": "09511533599127285786"
     },
     "user_tz": -330
    },
    "id": "HALplNdBPInh",
    "outputId": "52193568-8605-4d8c-f96e-909d0c33e7c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DET'),\n",
       " ('Lorillard', 'NOUN'),\n",
       " ('spokewoman', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " (',', '.'),\n",
       " ('``', '.'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('old', 'ADJ'),\n",
       " ('story', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BpRQ3Jh3PbhC"
   },
   "outputs": [],
   "source": [
    "X = []  # store input sequence\n",
    "Y = []  # store output sequence\n",
    "\n",
    "for sentence in tagged_sentences:\n",
    "    X_sentence = []\n",
    "    Y_sentence = []\n",
    "    for entity in sentence:\n",
    "        X_sentence.append(entity[0])  # entity[0] contains the word\n",
    "        Y_sentence.append(entity[1])  # entity[1] contains corresponding tag\n",
    "    X.append(X_sentence)\n",
    "    Y.append(Y_sentence)\n",
    "\n",
    "num_words = len(set([word.lower() for sentence in X for word in sentence]))\n",
    "num_tags = len(set([word.lower() for sentence in Y for word in sentence]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LGZ9cjvLPg5K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tagged sentences: 72202\n",
      "Vocabulary size: 59448\n",
      "Total number of tags: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of tagged sentences: {}\".format(len(X)))\n",
    "print(\"Vocabulary size: {}\".format(num_words))\n",
    "print(\"Total number of tags: {}\".format(num_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mZtiqqHJPiuT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample X:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
      "\n",
      "sample Y:  ['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('sample X: ', X[0], '\\n')\n",
    "print('sample Y: ', Y[0], '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LlAGgrzoPkwy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first input sequence  : 18\n",
      "Length of first output sequence : 18\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of first input sequence  : {}\".format(len(X[0])))\n",
    "print(\"Length of first output sequence : {}\".format(len(Y[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Y2_uK38TPmLy"
   },
   "outputs": [],
   "source": [
    "word_tokenizer = Tokenizer()  # instantiate tokenizer\n",
    "word_tokenizer.fit_on_texts(X)  # fit tokenizer on data\n",
    "X_encoded = word_tokenizer.texts_to_sequences(X)  # use the tokenizer to encode input sequence\n",
    "tag_tokenizer = Tokenizer()\n",
    "tag_tokenizer.fit_on_texts(Y)\n",
    "Y_encoded = tag_tokenizer.texts_to_sequences(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TOdtjjvXPpWj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Raw data point ** \n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "X:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
      "\n",
      "Y:  ['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.'] \n",
      "\n",
      "\n",
      "** Encoded data point ** \n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "X:  [6423, 24231, 2, 7652, 102, 170, 2, 47, 1898, 1, 269, 17, 7, 13230, 619, 1711, 2761, 3] \n",
      "\n",
      "Y:  [1, 1, 3, 11, 1, 6, 3, 2, 2, 5, 1, 4, 5, 6, 1, 1, 11, 3] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
    "print('X: ', X[0], '\\n')\n",
    "print('Y: ', Y[0], '\\n')\n",
    "print()\n",
    "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
    "print('X: ', X_encoded[0], '\\n')\n",
    "print('Y: ', Y_encoded[0], '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMzOoH9jDxCUsQ59ECkhkvr",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
