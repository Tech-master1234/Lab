{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23787,
     "status": "ok",
     "timestamp": 1726462032704,
     "user": {
      "displayName": "Mix Master",
      "userId": "09511533599127285786"
     },
     "user_tz": -330
    },
    "id": "2mK4eBIawm1E",
    "outputId": "4dd6459d-9e41-42a5-811b-7e33911a8a20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: watermark in c:\\users\\manoj\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: ipython>=6.0 in c:\\users\\manoj\\appdata\\roaming\\python\\python312\\site-packages (from watermark) (8.30.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\manoj\\anaconda3\\lib\\site-packages (from watermark) (7.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\manoj\\anaconda3\\lib\\site-packages (from watermark) (75.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\manoj\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->watermark) (3.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\manoj\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.0->watermark) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\manoj\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.0->watermark) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\manoj\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.0->watermark) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\manoj\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.0->watermark) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\manoj\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.0->watermark) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\manoj\\anaconda3\\lib\\site-packages (from ipython>=6.0->watermark) (2.15.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\manoj\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.0->watermark) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\manoj\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.0->watermark) (5.14.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\manoj\\appdata\\roaming\\python\\python312\\site-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\manoj\\appdata\\roaming\\python\\python312\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.0->watermark) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\manoj\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython>=6.0->watermark) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\manoj\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython>=6.0->watermark) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\manoj\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython>=6.0->watermark) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1726462032704,
     "user": {
      "displayName": "Mix Master",
      "userId": "09511533599127285786"
     },
     "user_tz": -330
    },
    "id": "QlIjJ8RTwM3n",
    "outputId": "0d4e83b2-f4c9-45aa-c120-36854f71a12e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Ethen\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.12.7\n",
      "IPython version      : 8.30.0\n",
      "\n",
      "keras     : 3.7.0\n",
      "numpy     : 1.26.4\n",
      "matplotlib: 3.9.2\n",
      "tensorflow: 2.18.0\n",
      "\n",
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "\u001b[1m600901/600901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3us/step\n",
      "corpus length: 600893\n",
      "example text: PREFACE\n",
      "\n",
      "\n",
      "SUPPOSING that Truth is a woman--what then? Is there not ground\n",
      "for suspecting that all philosophers, in so far as they have been\n",
      "dogmatists\n",
      "sampled original text:  ['PREFACE', 'SUPPOSING', 'that', 'Truth', 'is', 'a', 'woman', 'what', 'then?', 'Is']\n",
      "sampled cleaned text:  ['preface', 'supposing', 'that', 'truth', 'is', 'a', 'woman', 'what', 'then', 'is']\n",
      "vocabulary size:  5090\n",
      "filtered words:  5097\n",
      "sequence dimension:  (33342, 40)\n",
      "target dimension:  (33342, 5090)\n",
      "example sequence:\n",
      " [ 1  2  3  4  5  6  7  8  9  5 10 11 12 13  0  3 14 15 16 17 18 19 20 21\n",
      " 22 23 21 24 25 26 27  3 28 29 30 31 32  0 33 34]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from collections import Counter\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import get_file\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext watermark\n",
    "%watermark -a 'Ethen' -d -t -v -p keras,numpy,matplotlib,tensorflow\n",
    "\n",
    "def elapsed(sec):\n",
    "    \"\"\"\n",
    "    Converts elapsed time into a more human readable format.\n",
    "    from time import time\n",
    "\n",
    "    start = time()\n",
    "    # do something that's worth timing, like training a model\n",
    "    elapse = time() - start\n",
    "    elapsed(elapse)\n",
    "    \"\"\"\n",
    "    if sec < 60:\n",
    "        return str(sec) + ' seconds'\n",
    "    elif sec < (60 * 60):\n",
    "        return str(sec / 60) + ' minutes'\n",
    "    else:\n",
    "        return str(sec / (60 * 60)) + ' hours'\n",
    "\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print('corpus length:', len(raw_text))\n",
    "print('example text:', raw_text[:150])\n",
    "\n",
    "# ideally, we would save the cleaned text, to prevent\n",
    "# doing this step every single time\n",
    "tokens = raw_text.replace('--', ' ').split()\n",
    "cleaned_tokens = []\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "for word in tokens:\n",
    "    word = word.translate(table)\n",
    "    if word.isalpha():\n",
    "        cleaned_tokens.append(word.lower())\n",
    "\n",
    "print('sampled original text: ', tokens[:10])\n",
    "print('sampled cleaned text: ', cleaned_tokens[:10])\n",
    "\n",
    "# build up vocabulary,\n",
    "# rare words will also be considered out of vocabulary words,\n",
    "# this will be represented by an unknown token\n",
    "min_count = 2\n",
    "unknown_token = '<unk>'\n",
    "word2index = {unknown_token: 0}\n",
    "index2word = [unknown_token]\n",
    "\n",
    "filtered_words = 0\n",
    "counter = Counter(cleaned_tokens)\n",
    "for word, count in counter.items():\n",
    "    if count >= min_count:\n",
    "        index2word.append(word)\n",
    "        word2index[word] = len(word2index)\n",
    "    else:\n",
    "        filtered_words += 1\n",
    "\n",
    "num_classes = len(word2index)\n",
    "print('vocabulary size: ', num_classes)\n",
    "print('filtered words: ', filtered_words)\n",
    "\n",
    "# create semi-overlapping sequences of words with\n",
    "# a fixed length specified by the maxlen parameter\n",
    "step = 3\n",
    "maxlen = 40\n",
    "X = []\n",
    "y = []\n",
    "for i in range(0, len(cleaned_tokens) - maxlen, step):\n",
    "    sentence = cleaned_tokens[i:i + maxlen]\n",
    "    next_word = cleaned_tokens[i + maxlen]\n",
    "    X.append([word2index.get(word, 0) for word in sentence])\n",
    "    y.append(word2index.get(next_word, 0))\n",
    "\n",
    "# keras expects the target to be in one-hot encoded format,\n",
    "# ideally we would use a generator that performs this conversion\n",
    "# only on the batch of data that is currently required by the model\n",
    "# to be more memory-efficient\n",
    "X = np.array(X)\n",
    "Y = to_categorical(y, num_classes)\n",
    "print('sequence dimension: ', X.shape)\n",
    "print('target dimension: ', Y.shape)\n",
    "print('example sequence:\\n', X[0])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNANhGOsGTdubWW0YzWTQrD",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
